{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import yaml\n",
    "from   FaceBoxes import FaceBoxes\n",
    "from   TDDFA import TDDFA\n",
    "from   utils.functions import draw_landmarks\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from   utils.functions import cv_draw_landmark, get_suffix\n",
    "import imageio_ffmpeg\n",
    "import tqdm as tqdm\n",
    "import numpy as np\n",
    "\n",
    "from   tqdm import tqdm\n",
    "from   network1 import IDreveal\n",
    "from   numpy import load\n",
    "import statistics as stat \n",
    "\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import youtube_dl\n",
    "import sys\n",
    "import warnings\n",
    "from   os.path import join\n",
    "from   signal import signal, SIGINT, SIG_DFL\n",
    "from   detection import test_full_image_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,30):\n",
    "\n",
    "    video_fp_ = 'Dataset/Videos/00%{0}.mp4'.format(i)\n",
    "\n",
    "    fn = video_fp_.split('/')[-1]\n",
    "    reader = imageio.get_reader(video_fp_)\n",
    "    fps = reader.get_meta_data()['fps']\n",
    "    suffix = get_suffix(video_fp_)\n",
    "    video_wfp = f'Dataset/Results{fn.replace(suffix, \"\")}_3d.mp4'\n",
    "    writer = imageio.get_writer(video_wfp, fps=fps)\n",
    "\n",
    "    # face detection\n",
    "    face_boxes = FaceBoxes()\n",
    "\n",
    "    # regress 3DMM params\n",
    "    cfg = yaml.load(open('configs\\mb1_120x120.yml'), Loader=yaml.SafeLoader)\n",
    "    gpu_mode = cfg.get('gpu_mode', False)\n",
    "    tddfa = TDDFA(gpu_mode = gpu_mode, **cfg)\n",
    "\n",
    "\n",
    "    dense_flag = True\n",
    "    pre_ver = None\n",
    "    boxes = []\n",
    "    boxes_b = []\n",
    "    param_lst_b = []\n",
    "    for j, frame in (enumerate(reader)):\n",
    "        # print(frame)\n",
    "        frame_bgr = frame[..., ::-1]  # RGB->BGR\n",
    "        # print(frame_bgr)\n",
    "        # if i == 0:\n",
    "            # the first frame, detect face, here we only use the first face, you can change depending on your need\n",
    "        boxes = face_boxes(frame_bgr)\n",
    "        param_lst, roi_box_lst = tddfa(frame_bgr, boxes)\n",
    "        boxes_b = boxes_b + boxes\n",
    "        param_lst_b += param_lst\n",
    "        np.savez_compressed('Dataset/feats/00{0}.npz'.format(i),boxes_b,param_lst_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device   = 'cpu' # in ('cpu', 'cuda:0', 'cuda:1')\n",
    "time     = 100   # length of sequences in frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = IDreveal(time=time, device=device, weights_file='./model.th')\n",
    "def extract_embedding(x):\n",
    "    if isinstance(x, str):\n",
    "        x = np.load(x) # load 3ddfa features\n",
    "    y = net(x['arr_1']) # apply Temporal ID Network arr_1 contain the 3ddfa features array of vector have 62 coeff\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (range(0,5)):\n",
    "\n",
    "\n",
    "    ref_vids = [ 'Dataset/feats/reference/{0}'.format(i), ] # Reference Videos\n",
    "\n",
    "\n",
    "    # extract embedded vectors for reference videos\n",
    "    # print('Extracting embedded vectors for reference videos', flush=True)\n",
    "    y = extract_embedding('./%s.npz' % str(ref_vids[0]))\n",
    "    ref_embs = np.concatenate([extract_embedding('./%s.npz' % str(ref_vids[0]))], 0)\n",
    "    print(flush=True)\n",
    "    # print('Number of reference embedded vectors:', len(ref_embs), flush=True)\n",
    "\n",
    "\n",
    "    list_dist = list()\n",
    "    for j in tqdm(range(0,5)):    \n",
    "        test_vids =  [ # Test Videos \n",
    "            #(Video, Type),\n",
    "            'Dataset/feats/fake/{0}'.format(j),  1,\n",
    "        ]\n",
    "\n",
    "        typ_colors = ['C2', 'C3'] # color for each type of video\n",
    "        typ_labels = ['Real videos', 'Deepfakes'] # label for each type of video\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print('Extracting embedded vectors and distance computation for test videos', flush=True)\n",
    "        \n",
    "        count_embs = 0\n",
    "\n",
    "        embs = extract_embedding('./%s.npz' % test_vids[0]) # extract embedded vectors for a test video\n",
    "        count_embs = count_embs + len(embs)\n",
    "        dist = np.min(np.sum(np.square(ref_embs[None,:,:]-embs[:,None,:]),-1),-1) # compute distances\n",
    "        list_dist.append((dist, (test_vids[1])))\n",
    "        #Jihad(To show the number of embeded vector for each video)\n",
    "        #print('Total number of extracted vectors of video %s is:'%vid, len(embs), flush=True)\n",
    "        ##########################\n",
    "\n",
    "        print(flush=True)\n",
    "        print('Total number of extracted vectors:', count_embs, flush=True)\n",
    "    from cmath import sqrt\n",
    "    x = sqrt(1.1)\n",
    "    def set_color_violin(parts, color):\n",
    "        #utlity function to change the color of violin-plot\n",
    "        ret = None\n",
    "        for keys in parts:\n",
    "            if keys=='bodies':\n",
    "                for pc in parts['bodies']:\n",
    "                    ret = pc\n",
    "                    pc.set_facecolor(color)\n",
    "                    pc.set_edgecolor(color)\n",
    "            else:\n",
    "                parts[keys].set_edgecolor(color)\n",
    "                parts[keys].set_facecolor(color)\n",
    "        return ret\n",
    "    \n",
    "        \n",
    "    # show violin-plot\n",
    "    plt.figure(figsize=(15,8))\n",
    "    typ_id = [None for _ in typ_labels]\n",
    "    for i, (dist, typ) in enumerate(list_dist):\n",
    "        parts = plt.violinplot(dist, positions=(i+0.5,) ,showmedians=True, points=dist.size)\n",
    "        typ_id[typ] = set_color_violin(parts, typ_colors[typ])\n",
    "    \n",
    "    #Jihad \n",
    "    # print(list_dist)\n",
    "    # #Jihad The threshold value is sqrt(1.1)\n",
    "    # print(np.average(list_dist[7][0])) #mean value of distances for the video number 8 in testing videos\n",
    "    # print(np.median(list_dist[7][0]))  #median value of distances for the video number 8 in testing videos\n",
    "    \n",
    "    plt.xlim([0,len(list_dist)])\n",
    "    plt.xticks(np.arange(len(list_dist)),[])\n",
    "    plt.ylim([0.5,8.5])\n",
    "    plt.yticks([1,2,3,4,5,6,7,8,9,10,11],[], fontsize=10.0)\n",
    "    plt.ylabel('Squared Euclidean distance', fontsize=14.0)\n",
    "    plt.axhline(y = x.real + 0.5, color = 'b', linestyle = '-')\n",
    "    plt.legend(typ_id,  typ_labels, bbox_to_anchor=(1.04, 1), loc='upper left', fontsize=12.0)\n",
    "    plt.grid()\n",
    "    plt.show()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import sqrt\n",
    "x = sqrt(1.1)\n",
    "TP = 0\n",
    "TN = 0 \n",
    "FP = 0 \n",
    "FN = 0\n",
    "print(list_dist)\n",
    "print(len(list_dist))    \n",
    "for i, (dist, typ) in enumerate(list_dist):\n",
    "    median = np.median(list_dist[i][0])\n",
    "    if (median < x.real) & typ == 0: \n",
    "        TP += 1\n",
    "    elif (median > x.real) & typ == 1: \n",
    "        TN += 1\n",
    "    elif (median < x.real) & typ == 1: \n",
    "        FP += 1\n",
    "    elif (median > x.real) & typ == 0:\n",
    "        FN += 1\n",
    "\n",
    "acc = (TP + TN)/(TP + TN +FP + FN)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'models/x-model23.p'\n",
    "import os\n",
    "path_of_the_directory = 'E:\\drivers'\n",
    "ext = ('.mp4')\n",
    "for files in os.listdir('Dataset/Videos/all/'):\n",
    "    if files.endswith(ext):\n",
    "\n",
    "        # video_path = files\n",
    "        prediction = None\n",
    "        prediction = test_full_image_network(video_path='Dataset/Videos/all/' + files,model_path= model, \n",
    "        start_frame= 0, output_path= \"videoOut\",fast='store_true')\n",
    "        print(\"Prediction of it being fake in video{0}: \".format(files) + str(prediction[\"score\"]))\n",
    "        print(\"Output video in: \" + prediction[\"file\"]) \n",
    "    if files.__contains__('005'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble model\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "estimators = []\n",
    "estimators.append(('id_reveal', net))\n",
    "estimators.append(('xception', model))\n",
    "\n",
    "modelStack = AdaBoostRegressor(estimators)\n",
    "# modelStack.fit(X_train, y_train)\n",
    "# predictionStackingClass= modelStack.predict(X_test)\n",
    "# print(\"Train Accuracy:\",modelStack.score(X_train, y_train))\n",
    "# print(\"Test Accuracy:\",modelStack.score(X_test, y_test))\n",
    "# print(classification_report(y_test,predictionStackingClass))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
